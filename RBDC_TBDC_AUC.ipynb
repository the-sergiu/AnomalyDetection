{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3fe2b69-9137-4060-8a4e-44eae12d6065",
   "metadata": {},
   "source": [
    "## Runs\n",
    "\n",
    "#### Baseline using random noise:\n",
    "```py\n",
    "tbdc = 0.09724496333736742\n",
    "rbdc = 0.04066706907997272\n",
    "```\n",
    "\n",
    "#### decoder_t8_preds_detr101dc5_adamw_numblocks_1_ffdim_4096_heads_16\n",
    "```py\n",
    "tbdc = 0.26097236334297624\n",
    "rbdc = 0.2478526008210725\n",
    "```\n",
    "\n",
    "#### decoder_t8_preds_detr101dc5_adamw_numblocks_1_ffdim_4096_heads_16_v2 (trained on Shanghai)\n",
    "```py\n",
    "tbdc = 0.10937038211545225\n",
    "rbdc = 0.1109098488822660\n",
    "```\n",
    "\n",
    "#### decoder_state_dict_adamw_40e_numblocks_2_ffdim_4096_heads_16_mseloss_0.05\n",
    "```py\n",
    "tbdc = 0.27224404650189515\n",
    "rbdc = 0.2695939567044897\n",
    "```\n",
    "\n",
    "#### decoder_v2_t8_preds_detr101dc5_adamw_numblocks_1_ffdim_4096_heads_1 (v3)\n",
    "```py\n",
    "tbdc = 0.28874330979762747\n",
    "rbdc = 0.28412440159860\n",
    "```\n",
    "\n",
    "#### decoder_v2_t8_preds_detr101dc5_adamw_numblocks_1_ffdim_4096_heads_32.pth\n",
    "```py\n",
    "tbdc = 0.2881355018110197\n",
    "rbdc = 0.2746187377346972\n",
    "\n",
    "Macro AUC: 0.695; Micro AUC: 0.668\n",
    "```\n",
    "\n",
    "#### decoder_v2_t8_preds_yolov8_adamw_numblocks_1_ffdim_4096_heads_16.pth with YOLOv8 preds\n",
    "```py\n",
    "tbdc = 0.3000759355497022\n",
    "rbdc = 0.2961878808637868\n",
    "\n",
    "Macro AUC:0.66?; Micro AUC:0.625\n",
    "\n",
    "Baseline: \n",
    "tbdc = 0.000\n",
    "rbdc = 0.000\n",
    "```\n",
    "\n",
    "#### autoencoder_ft_t8_decoder_v2_epoch_5 with DETR 101 DC5 preds, obj_dect_avenue_detr_resnet101_dc5 obj\n",
    "```py\n",
    "tbdc = 0.18709753619342853\r\n",
    "rbdc = 0.20189405352643836\n",
    "\n",
    "Macro AUC:0.660 ; Micro AUC0.664:\n",
    "```\n",
    "\n",
    "#### autoencoder_ft_t8_decoder_v2_trained_avenue_loss_0.003 with DETR 101 DC5 Preds, obj_dect_avenue_detr_resnet101_dc5 obj\n",
    "```py\n",
    "tbdc = 0.17969921324730181\r\n",
    "rbdc = 0.18816193287500632\n",
    "\n",
    "Macro AUC:0.653 ; Micro AUC 0.655:\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f234ae18-0b83-4f40-8a8a-beb4106282d8",
   "metadata": {},
   "source": [
    "#### autoencoder_ft_t8_decoder_v2_yolov8_epoch_17 with YOLO v8 pre (no predict params)\n",
    "```py\n",
    "tbdc = 0.14231983104340193\n",
    "rbdc = 0.15282977450316226\n",
    "Macro AUC: 0.727; Micro AUC: 0.43\n",
    "\n",
    "```\n",
    "\n",
    "#### autoencoder_ft_t8_decoder_v2_yolov8_new_epoch_20_mseloss_0.007056034170091152\n",
    "```py\n",
    "tbdc = 0.18441444414961888\r\n",
    "rbdc = 0.183827570099877\n",
    "Macro AUC: 0.5826279864736656; Micro AUC: 0.59926857078780697\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b599d7-c124-4e69-bfcc-e483ff77b5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Sergiu/Desktop/AnomalyDetection\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "from enum import Enum\n",
    "\n",
    "import cv2 as cv\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "import pdb\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.append('./abnorm_event_detect/evaluation/')\n",
    "os.chdir('abnorm_event_detect')\n",
    "\n",
    "from evaluation.merge_tracks import ContinuousTrack\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0bdcff-c23f-4eb8-bddb-b8e0bbb5602f",
   "metadata": {},
   "source": [
    "## Define Functions for RBDC, TBDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8f3355-0000-4785-92f7-f4c8e8a79e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackState(Enum):\n",
    "    CREATED = \"created\"\n",
    "    UPDATED = \"updated\"\n",
    "    CLOSED = \"closed\"\n",
    "\n",
    "class Track:\n",
    "    def __init__(self, start_idx=0, end_idx=None, mask=0, video_name=\"\"):\n",
    "        self.start_idx = start_idx\n",
    "        self.end_idx = end_idx\n",
    "        self.bboxes = {}\n",
    "        self.mask = mask\n",
    "        self.state = TrackState.CREATED\n",
    "        self.video_name = video_name\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__class__) + \": \" + str(self.__dict__)\n",
    "\n",
    "class AnomalyDetection:\n",
    "    def __init__(self, frame_idx, bbox, score, video_name, track_id=-1):\n",
    "        self.frame_idx = frame_idx\n",
    "        self.bbox = bbox\n",
    "        self.score = score\n",
    "        self.video_name = video_name\n",
    "        self.track_id = track_id\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__class__) + \": \" + str(self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecc7998-8871-4950-a688-151184a895e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the intersection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d721fdd-8e78-48eb-afcd-ade926e2297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc_v3(video_info_path):\n",
    "    file_names = os.listdir(os.path.join(video_info_path, \"meta_0.800\"))\n",
    "    video_loc_v3 = []\n",
    "    for file_name in file_names:\n",
    "        loc_v3 = np.loadtxt(os.path.join(video_info_path, \"meta_0.800\", file_name))\n",
    "\n",
    "        video_loc_v3.append(loc_v3[:5])\n",
    "    return video_loc_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "828d00b5-7ff4-4b5f-8b9e-234eda4bceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_anomalies_per_video(output_path, video_name, size):\n",
    "    \"\"\"\n",
    "    :param output_path\n",
    "    :param video_name\n",
    "    :param size = H, W\n",
    "    \"\"\"\n",
    "\n",
    "    # compute anomaly detection from predicted heat map\n",
    "    loc_v3 = np.load(os.path.join(args.output_folder_base, args.database_name, \"test\",\n",
    "                                  video_name, \"loc_v3_%f.npy\" % args.lambda_))\n",
    "    # locv3 format [[frame_idx, x_min, y_min, x_max, y_max]]\n",
    "\n",
    "    ab_event = np.load(os.path.join(args.output_folder_base, args.database_name, \"test\",\n",
    "                                    video_name, \"ab_event3_%f.npy\" % args.lambda_))\n",
    "\n",
    "    ab_event_resized = []\n",
    "    for i in range(ab_event.shape[2]):\n",
    "        res = cv.resize(ab_event[:, :, i], (size[1], size[0]))\n",
    "        ab_event_resized.append(res)\n",
    "\n",
    "    pred_anomalies_detected = []\n",
    "    for idx in range(len(loc_v3)):\n",
    "        frame_idx = int(loc_v3[idx][0])\n",
    "        bbox = loc_v3[idx][1:]\n",
    "        bbox = [int(b) for b in bbox]\n",
    "        crop_frame = ab_event_resized[frame_idx][bbox[1]: bbox[3], bbox[0]: bbox[2]]\n",
    "        pred_anomalies_detected.append(AnomalyDetection(frame_idx, bbox, crop_frame.max(), video_name))\n",
    "\n",
    "    return pred_anomalies_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ab6fd6-3790-4ec6-ae3a-e0a9b1b1d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_predicted_anomalies(output_path, resolution=()):\n",
    "    video_names = os.listdir(output_path)\n",
    "    video_names.sort()\n",
    "    pred_anomalies = []\n",
    "    num_frames = 0\n",
    "    for video_name in video_names:\n",
    "        if os.path.isfile(os.path.join(output_path, video_name)):\n",
    "            continue\n",
    "        video_meta_data = pickle.load(open(os.path.join(output_path, video_name, \"video_meta_data.pkl\"), 'rb'))\n",
    "        video_size = (video_meta_data['height'], video_meta_data['width'])  # h, w\n",
    "        num_frames_video = video_meta_data['num_frames']\n",
    "        pred = get_predicted_anomalies_per_video(output_path, video_name, video_size)\n",
    "        # save_txt_predicted(pred, video_name)\n",
    "        pred_anomalies += pred\n",
    "        num_frames += num_frames_video\n",
    "\n",
    "    return pred_anomalies, num_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4da1b3-b80c-4a70-96f8-ac3320134b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(pred_anomaly, gt_anomalies_per_frame):\n",
    "    max_iou = 0\n",
    "    idx = -1\n",
    "    for index, gt_anomaly in enumerate(gt_anomalies_per_frame):\n",
    "        iou = bb_intersection_over_union(gt_anomaly.bbox, pred_anomaly.bbox)\n",
    "        if max_iou < iou:\n",
    "            max_iou = iou\n",
    "            idx = index\n",
    "\n",
    "    return max_iou, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6278adc5-11a0-448a-b161-0779d267f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_gt_indices(pred_anomaly, gt_anomalies_per_frame, beta):\n",
    "    indices = []\n",
    "    for index, gt_anomaly in enumerate(gt_anomalies_per_frame):\n",
    "        iou = bb_intersection_over_union(gt_anomaly.bbox, pred_anomaly.bbox)\n",
    "        if iou >= beta:\n",
    "            indices.append(index)\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab7d1984-111f-47d9-a56e-98a27024dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tbdr(gt_tracks, num_matched_detections_per_track, alpha):\n",
    "    percentages = np.array([x / len(y.bboxes) for x, y in zip(num_matched_detections_per_track, gt_tracks)])\n",
    "    return np.sum(percentages >= alpha) / len(num_matched_detections_per_track)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e8a562-c9a1-4818-8042-a23cc49fc6b6",
   "metadata": {},
   "source": [
    "## V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c47994ea-b79b-4518-9725-9357fce29c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from enum import Enum\n",
    "\n",
    "import cv2 as cv\n",
    "import scipy.io as sio\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import pdb\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from evaluation.merge_tracks import ContinuousTrack\n",
    "\n",
    "\n",
    "class TrackState(Enum):\n",
    "    CREATED = \"created\"\n",
    "    UPDATED = \"updated\"\n",
    "    CLOSED = \"closed\"\n",
    "\n",
    "\n",
    "class Track:\n",
    "    def __init__(self, start_idx=0, end_idx=None, mask=0, video_name=\"\"):\n",
    "        self.start_idx = start_idx\n",
    "        self.end_idx = end_idx\n",
    "        self.bboxes = {}\n",
    "        self.mask = mask\n",
    "        self.state = TrackState.CREATED\n",
    "        self.video_name = video_name\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__class__) + \": \" + str(self.__dict__)\n",
    "\n",
    "class AnomalyDetection:\n",
    "    def __init__(self, frame_idx, bbox, score, video_name, track_id=-1):\n",
    "        self.frame_idx = frame_idx\n",
    "        self.bbox = bbox\n",
    "        self.score = score\n",
    "        self.video_name = video_name\n",
    "        self.track_id = track_id\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__class__) + \": \" + str(self.__dict__)\n",
    "\n",
    "\n",
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the intersection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "\n",
    "def get_loc_v3(video_info_path):\n",
    "    file_names = os.listdir(os.path.join(video_info_path, \"meta_0.800\"))\n",
    "    video_loc_v3 = []\n",
    "    for file_name in file_names:\n",
    "        loc_v3 = np.loadtxt(os.path.join(video_info_path, \"meta_0.800\", file_name))\n",
    "\n",
    "        video_loc_v3.append(loc_v3[:5])\n",
    "    return video_loc_v3\n",
    "\n",
    "\n",
    "def get_predicted_anomalies_per_video(output_path, video_name, size):\n",
    "    \"\"\"\n",
    "    :param output_path\n",
    "    :param video_name\n",
    "    :param size = H, W\n",
    "    \"\"\"\n",
    "\n",
    "    # compute anomaly detection from predicted heat map\n",
    "    loc_v3 = np.load(os.path.join(args.output_folder_base, args.database_name, \"test\",\n",
    "                                  video_name, \"loc_v3_%f.npy\" % args.lambda_))\n",
    "    # locv3 format [[frame_idx, x_min, y_min, x_max, y_max]]\n",
    "\n",
    "    ab_event = np.load(os.path.join(args.output_folder_base, args.database_name, \"test\",\n",
    "                                    video_name, \"ab_event3_%f.npy\" % args.lambda_))\n",
    "\n",
    "    ab_event_resized = []\n",
    "    for i in range(ab_event.shape[2]):\n",
    "        res = cv.resize(ab_event[:, :, i], (size[1], size[0]))\n",
    "        ab_event_resized.append(res)\n",
    "\n",
    "    pred_anomalies_detected = []\n",
    "    for idx in range(len(loc_v3)):\n",
    "        frame_idx = int(loc_v3[idx][0])\n",
    "        bbox = loc_v3[idx][1:]\n",
    "        bbox = [int(b) for b in bbox]\n",
    "        crop_frame = ab_event_resized[frame_idx][bbox[1]: bbox[3], bbox[0]: bbox[2]]\n",
    "        pred_anomalies_detected.append(AnomalyDetection(frame_idx, bbox, crop_frame.max(), video_name))\n",
    "\n",
    "    return pred_anomalies_detected\n",
    "\n",
    "\n",
    "def save_txt_predicted(preds, video_name):\n",
    "    predictions = []\n",
    "    for pred in preds:  # [frame_id, x_min, y_min, x_max, y_max, anomaly_score]\n",
    "        predictions.append([pred.frame_idx] + pred.bbox + [pred.score])\n",
    "    np.savetxt(f'avenue/det/{video_name}.txt', predictions, delimiter=',')\n",
    "\n",
    "\n",
    "def get_all_predicted_anomalies(output_path):\n",
    "    video_names = os.listdir(output_path)\n",
    "    video_names.sort()\n",
    "    pred_anomalies = []\n",
    "    num_frames = 0\n",
    "    for video_name in video_names:\n",
    "        if os.path.isfile(os.path.join(output_path, video_name)):\n",
    "            continue\n",
    "        video_meta_data = pickle.load(open(os.path.join(output_path, video_name, \"video_meta_data.pkl\"), 'rb'))\n",
    "        video_size = (video_meta_data['height'], video_meta_data['width'])  # h, w\n",
    "        num_frames_video = video_meta_data['num_frames']\n",
    "        pred = get_predicted_anomalies_per_video(output_path, video_name, video_size)\n",
    "        # save_txt_predicted(pred, video_name)\n",
    "        pred_anomalies += pred\n",
    "        num_frames += num_frames_video\n",
    "\n",
    "    return pred_anomalies, num_frames\n",
    "\n",
    "\n",
    "def compute_iou(pred_anomaly, gt_anomalies_per_frame):\n",
    "    max_iou = 0\n",
    "    idx = -1\n",
    "    for index, gt_anomaly in enumerate(gt_anomalies_per_frame):\n",
    "        iou = bb_intersection_over_union(gt_anomaly.bbox, pred_anomaly.bbox)\n",
    "        if max_iou < iou:\n",
    "            max_iou = iou\n",
    "            idx = index\n",
    "\n",
    "    return max_iou, idx\n",
    "\n",
    "\n",
    "def get_matching_gt_indices(pred_anomaly, gt_anomalies_per_frame, beta):\n",
    "    indices = []\n",
    "    for index, gt_anomaly in enumerate(gt_anomalies_per_frame):\n",
    "        iou = bb_intersection_over_union(gt_anomaly.bbox, pred_anomaly.bbox)\n",
    "        if iou >= beta:\n",
    "            indices.append(index)\n",
    "\n",
    "    return indices\n",
    "\n",
    "\n",
    "def compute_tbdr(gt_tracks, num_matched_detections_per_track, alpha):\n",
    "    percentages = np.array([x / len(y.bboxes) for x, y in zip(num_matched_detections_per_track, gt_tracks)])\n",
    "    return np.sum(percentages >= alpha) / len(num_matched_detections_per_track)\n",
    "\n",
    "\n",
    "def compute_fpr_rbdr(pred_anomalies_detected: [AnomalyDetection], gt_anomalies: [AnomalyDetection], all_gt_tracks,\n",
    "                     num_frames, num_tracks, alpha=0.1, beta=0.1):\n",
    "    num_matched_detections_per_track = [0] * num_tracks\n",
    "\n",
    "    # TODO: add pixel level IOU\n",
    "    num_detected_anomalies = len(pred_anomalies_detected)\n",
    "    gt_anomaly_video_per_frame_dict = {}\n",
    "    found_gt_anomaly_video_per_frame_dict = {}\n",
    "\n",
    "    for anomaly in gt_anomalies:\n",
    "        anomalies_per_frame = gt_anomaly_video_per_frame_dict.get((anomaly.video_name, anomaly.frame_idx), None)\n",
    "        if anomalies_per_frame is None:\n",
    "            gt_anomaly_video_per_frame_dict[(anomaly.video_name, anomaly.frame_idx)] = [anomaly]\n",
    "            found_gt_anomaly_video_per_frame_dict[(anomaly.video_name, anomaly.frame_idx)] = [0]\n",
    "        else:\n",
    "            gt_anomaly_video_per_frame_dict[(anomaly.video_name, anomaly.frame_idx)].append(anomaly)\n",
    "            found_gt_anomaly_video_per_frame_dict[(anomaly.video_name, anomaly.frame_idx)].append(0)\n",
    "\n",
    "    tp = np.zeros(num_detected_anomalies)\n",
    "    fp = np.zeros(num_detected_anomalies)\n",
    "    tbdr = np.zeros(num_detected_anomalies)\n",
    "    remove_idx = []\n",
    "    pred_anomalies_detected.sort(key=lambda anomaly_detection: anomaly_detection.score, reverse=True)\n",
    "    for idx, pred_anomaly in enumerate(pred_anomalies_detected):\n",
    "        gt_anomalies_per_frame = gt_anomaly_video_per_frame_dict.get((pred_anomaly.video_name, pred_anomaly.frame_idx),\n",
    "                                                                     None)\n",
    "\n",
    "        if gt_anomalies_per_frame is None:\n",
    "            fp[idx] = 1\n",
    "        else:\n",
    "            matching_gt_bboxes_indices = get_matching_gt_indices(pred_anomaly, gt_anomalies_per_frame, beta)\n",
    "            if len(matching_gt_bboxes_indices) > 0:\n",
    "                non_matched_indices = []\n",
    "                for matched_ind in matching_gt_bboxes_indices:\n",
    "                    if found_gt_anomaly_video_per_frame_dict.get((pred_anomaly.video_name,\n",
    "                                                                  pred_anomaly.frame_idx))[matched_ind] == 0:\n",
    "                        non_matched_indices.append(matched_ind)\n",
    "                        found_gt_anomaly_video_per_frame_dict.get((pred_anomaly.video_name, pred_anomaly.frame_idx))[\n",
    "                            matched_ind] = 1\n",
    "                        num_matched_detections_per_track[gt_anomalies_per_frame[matched_ind].track_id] += 1\n",
    "\n",
    "                tp[idx] = len(non_matched_indices)\n",
    "\n",
    "            else:\n",
    "                fp[idx] = 1\n",
    "\n",
    "        tbdr[idx] = compute_tbdr(all_gt_tracks, num_matched_detections_per_track, alpha)\n",
    "\n",
    "    cum_false_positive = np.cumsum(fp)\n",
    "    cum_true_positive = np.cumsum(tp)\n",
    "    # add the point (0, 0) for each vector\n",
    "    cum_false_positive = np.concatenate(([0], cum_false_positive))\n",
    "    cum_true_positive = np.concatenate(([0], cum_true_positive))\n",
    "    tbdr = np.concatenate(([0], tbdr))\n",
    "\n",
    "    rbdr = cum_true_positive / len(gt_anomalies)\n",
    "    fpr = cum_false_positive / num_frames\n",
    "\n",
    "    idx_1 = np.where(fpr <= 1)[0][-1] + 1\n",
    "\n",
    "    if fpr[idx_1 - 1] != 1:\n",
    "        print('fpr does not reach 1')\n",
    "        rbdr = np.insert(rbdr, idx_1, rbdr[idx_1 - 1])\n",
    "        tbdr = np.insert(tbdr, idx_1, tbdr[idx_1 - 1])\n",
    "        fpr = np.insert(fpr, idx_1, 1)\n",
    "        idx_1 += 1\n",
    "\n",
    "    tbdc = metrics.auc(fpr[:idx_1], tbdr[:idx_1])\n",
    "    rbdc = metrics.auc(fpr[:idx_1], rbdr[:idx_1])\n",
    "\n",
    "    print('tbdc = ' + str(tbdc))\n",
    "    print('rbdc = ' + str(rbdc))\n",
    "    return rbdc, tbdc\n",
    "\n",
    "    # print(tbdr[idx_1 - 1], rbdr[idx_1 - 1])\n",
    "    # plt.plot(fpr, rbdr, '-')\n",
    "    # plt.xlabel('FPR')\n",
    "    # plt.ylabel('RBDR')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "# def save_tracks_as_txt(tracks, video_name):\n",
    "#     regions = []\n",
    "#     for track_id, track in enumerate(tracks):\n",
    "#         for frame_idx, bbox in track.bboxes.items():\n",
    "#             regions.append([track_id] + [frame_idx] + bbox)\n",
    "#     np.savetxt(f'avenue/tracks/{video_name}.txt', regions, delimiter=',')\n",
    "\n",
    "\n",
    "def compute_rbdc_tbdc_func(predictions_dir, gt_dir, num_frames):\n",
    "    video_names = [os.path.basename(x) for x in glob.glob(os.path.join(predictions_dir, \"*\")) if os.path.isdir(x)]\n",
    "\n",
    "    # Get GT for RBDC and TBDC\n",
    "    all_gt_tracks = []\n",
    "    num_tracks = 0\n",
    "    for vn in video_names:\n",
    "        tracks = pickle.load(open(os.path.join(gt_dir, f\"{vn}.pkl\"), 'rb'))\n",
    "        all_gt_tracks += tracks\n",
    "        num_tracks += len(tracks)\n",
    "\n",
    "    gt_anomalies = []\n",
    "    for track_id, track in enumerate(all_gt_tracks):\n",
    "        for frame_idx, bbox in track.bboxes.items():\n",
    "            gt_anomalies.append(AnomalyDetection(frame_idx, bbox, 1, track.video_name, track_id=track_id))\n",
    "\n",
    "    # Get Preds for RBDC and TBDC\n",
    "    nr_thresholds = 10\n",
    "    all_pred_ano = []\n",
    "    for vn in video_names:\n",
    "        frames = list(glob.glob(os.path.join(predictions_dir, vn, \"*.jpg\")))\n",
    "        frames = sorted(frames, key=lambda filename: int(''.join(filter(str.isdigit, filename))))\n",
    "        # for frame in frames:\n",
    "        for f_idx, frame in enumerate(frames):\n",
    "            # frame read\n",
    "            f = np.array(np.load(frame))\n",
    "            thresholds = np.linspace(f.min(), f.max(), nr_thresholds + 2)[1:-1]\n",
    "            for thr in thresholds:\n",
    "                th_f = f.copy()\n",
    "                th_f[f < thr] = 0.0\n",
    "                th_f[f >= thr] = 1.0\n",
    "\n",
    "                num_labels, labels, bboxes, centroids = cv.connectedComponentsWithStats(th_f.astype(np.uint8), connectivity=8)\n",
    "                for box in bboxes:\n",
    "                    b = np.array([box[0], box[0], box[0] + box[2], box[1] + box[3]]) # x_min, y_min, x_max, y_max\n",
    "                    score = f[b[1]:b[3], b[0]:b[2]].max()\n",
    "                    all_pred_ano.append(AnomalyDetection(f_idx, b, score, vn, track_id=-1))\n",
    "\n",
    "    return compute_fpr_rbdr(gt_anomalies, gt_anomalies, all_gt_tracks, num_frames, num_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c749f08-fa67-4836-b131-6dad1f38951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpr does not reach 1\n",
      "tbdc = 0.0\n",
      "rbdc = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6088/3134289015.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  rbdr = cum_true_positive / len(gt_anomalies)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(nan, 0.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_dir = './datasets/Avenue Dataset/objects/test/'\n",
    "gt_dir = './tracks/tracks_avenue/'\n",
    "compute_rbdc_tbdc_func(predictions_dir=gt_dir, gt_dir=gt_dir, num_frames=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18d6f8a-c776-488d-baf5-d5378dea00d2",
   "metadata": {},
   "source": [
    "## Initialize Ground Truths for Anomaly Det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6a0493a-5b50-4ea2-acdb-af73c694de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(directory, file_types=['*.pkl']):\n",
    "    files = []\n",
    "    for file_type in file_types:\n",
    "        files.extend(glob.glob(os.path.join(directory, file_type)))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4390a524-ce00-4840-a9e7-dc0180e6d3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '02', '03']\n",
      "['./tracks/tracks_avenue/01.pkl', './tracks/tracks_avenue/02.pkl', './tracks/tracks_avenue/03.pkl']\n"
     ]
    }
   ],
   "source": [
    "path = './tracks/tracks_avenue/'\n",
    "video_names = [file.split('/')[-1].split('.')[0] for file in list_files(path) if 'cont' not in file]\n",
    "pkl_files = [file for file in list_files(path) if 'cont' not in file]\n",
    "print(video_names[:3])\n",
    "print(pkl_files[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d7cb9fa-967c-47c7-9f42-bbdb8eac130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All GT Tracks:  121 [<evaluation.track.Track object at 0x7fa5e07088e0>, <evaluation.track.Track object at 0x7fa5968cc790>]\n",
      "GT Anomalies:  3914 [<__main__.AnomalyDetection object at 0x7fa5f37743a0>, <__main__.AnomalyDetection object at 0x7fa5968cd270>]\n"
     ]
    }
   ],
   "source": [
    "# Get GT for RBDC and TBDC\n",
    "all_gt_tracks = []\n",
    "num_tracks = 0\n",
    "\n",
    "for vn, pkl_file in zip(video_names, pkl_files):\n",
    "    tracks = pickle.load(open(os.path.join(pkl_file), 'rb'))\n",
    "    all_gt_tracks += tracks\n",
    "\n",
    "num_tracks = len(all_gt_tracks)\n",
    "print(\"All GT Tracks: \", num_tracks, all_gt_tracks[:2])\n",
    "\n",
    "gt_anomalies = []\n",
    "for track_id, track in enumerate(all_gt_tracks):\n",
    "    for frame_idx, bbox in track.bboxes.items():\n",
    "        gt_anomalies.append(AnomalyDetection(frame_idx, bbox, 1, track.video_name, track_id=track_id))\n",
    "\n",
    "print(\"GT Anomalies: \", len(gt_anomalies), gt_anomalies[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a9c737-0a18-40a6-ad86-d7d706be9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# dataset_test_dir = './datasets/Avenue Dataset/predictions/test'\n",
    "\n",
    "# # Get Preds for RBDC and TBDC\n",
    "# nr_thresholds = 10\n",
    "# all_pred_ano = []\n",
    "# for vn in video_names:\n",
    "#     frames = list(glob.glob(os.path.join(dataset_test_dir, vn, \"*.jpg\")))\n",
    "#     frames = sorted(frames, key=lambda filename: int(''.join(filter(str.isdigit, filename))))\n",
    "#     # for frame in frames:\n",
    "#     for f_idx, frame in enumerate(frames):\n",
    "#         # frame read\n",
    "#         f = np.array(Image.open(frame))\n",
    "#         thresholds = np.linspace(f.min(), f.max(), nr_thresholds + 2)[1:-1]\n",
    "#         for thr in thresholds:\n",
    "#             th_f = f.copy()\n",
    "#             th_f[f < thr] = 0.0\n",
    "#             th_f[f >= thr] = 1.0\n",
    "\n",
    "#             src = cv.cvtColor(th_f, cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "#             num_labels, labels, bboxes, centroids = cv.connectedComponentsWithStats(src.astype(np.uint8), connectivity=8)\n",
    "#             for box in bboxes:\n",
    "#                 b = np.array([box[0], box[0], box[0] + box[2], box[1] + box[3]]) # x_min, y_min, x_max, y_max\n",
    "#                 try:\n",
    "#                     score = f[b[1]:b[3], b[0]:b[2]].max()\n",
    "#                 except:\n",
    "#                     pass\n",
    "#                 all_pred_ano.append(AnomalyDetection(f_idx, b, score, vn, track_id=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df858316-f9e8-4fa2-a17e-998e4807dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(all_pred_ano), all_pred_ano[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "917a5d5d-482b-410f-b848-b7fcd2e3f4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_pred_ano[1].frame_idx, all_pred_ano[1].bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30392109-4157-4c8f-9543-9b5edb453287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_anomalies[0].frame_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc87f2-92a0-4c28-ad4f-bf08d356c6eb",
   "metadata": {},
   "source": [
    "- in loc de gt_anomalies o sa am all_pred_ano pe care le compun cum am discutat\n",
    "- suma tuturor frame urilor peste tot pe train/test/de testat (num_frames) -> le adun in baza unui index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66ef66a7-e1d5-405a-bd85-78c787790f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpr does not reach 1\n",
      "tbdc = 1.0\n",
      "rbdc = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_fpr_rbdr(gt_anomalies, gt_anomalies, all_gt_tracks, num_frames=1000, num_tracks=num_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4395202e-9631-4477-b514-885f7fb089b9",
   "metadata": {},
   "source": [
    "1. Cum construiesc si ce am nevoie pt prediction tracks?\n",
    "2. Cum 'detectez' o anomalie pentru a construi aceste anomaly tracks?\n",
    "3. Ca si cod, cam care e ordinea rularilor? De ce mai am nevoie? Ruleaza deja bucata de `compute_rbdc_tbdc_func`, dar nu stiu exact cum sa apelez corect `compute_fpr_rbdr`.\n",
    "4. Obtin all_pred_ano sa zicem - ar trebui salvat unedva pentru a fi apelat acel prediction path de catre `compute_fpr_rbdr`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422b2566-dd96-486b-8818-20f244d0e7c5",
   "metadata": {},
   "source": [
    "- am bounding boxes pt obiecte, le bag in AE si obtin mle loss (anomaly score).\n",
    "- frame index, b - bounding box [xmin, ymin, xmax, ymax], score=score (mle), vn= video name, track_id=-1\n",
    "- eventual saLVEZ TOTUL INTR-UN CSV PE CARE IL IMPORT CU PANDAS\n",
    "- trebuie sa imi fac eu parsarea de frame uri, bounding boxes pe obj det, si creez tot\n",
    "- all_pred_ano.append(AnomalyDetection(f_idx, b, score, vn, track_id=-1))\n",
    "- sfat: sa imi creez pentru fiecare video, sa imi fac un pkl/obj pe care il salvez pe disk in care am (f_idx, boundingbox) -> ca asta scoate object detectorul si asta salvez pe disk.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12db351f-3133-4cdd-864c-54571287e739",
   "metadata": {},
   "source": [
    "## Import AutoEncoder which will be used to compute Anomaly Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7b32744-e2a0-423e-893f-255423c32ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If for semantic segmentation, please install mmsegmentation first\n",
      "If for detection, please install mmdetection first\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./ml-fastvit')\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import models\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from timm.models import create_model\n",
    "from models.modules.mobileone import reparameterize_model\n",
    "from PIL import Image\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# from UpsampleTransformerDecoder import UpsampleTransformerDecoder\n",
    "from UpsampleTransformerDecoderV2 import UpsampleTransformerDecoderV2\n",
    "\n",
    "# Before starting the training, make sure to clear any residual memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7095eff6-6eae-4355-9c8d-17dfa3f12271",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_transform = T.Compose([\n",
    "        T.Resize((64, 64)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c49b07-e265-4a2a-bc95-5597709935cf",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2abdb7f1-2f3a-41e0-8045-999006c406e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_model(\"fastvit_t8\", fork_feat=True) # can turn fork_feat to False\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "decoder = UpsampleTransformerDecoderV2(\n",
    "    input_channels=384,\n",
    "    num_upsamples=5,  # Adjusted to 5 upsampling steps\n",
    "    num_blocks=1,\n",
    "    num_heads=8,\n",
    "    ff_dim=2048,\n",
    "    output_channels=3\n",
    ")\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e1057a0-b44b-4252-ae8f-1ab7e714ee0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_path = 'autoencoder_ft_t8_decoder_v2_yolov8_new_epoch_20_mseloss_0.007056034170091152.pth'\n",
    "encoder.load_state_dict(torch.load(autoencoder_path)['encoder_state_dict'])\n",
    "decoder.load_state_dict(torch.load(autoencoder_path)['decoder_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d253501-b9ea-43b7-b332-6087a306717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x[-1])\n",
    "        return x\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "autoencoder = autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51928de9-e883-4405-9a2d-bd2d29cf546a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cedc81ff-676b-44a1-96b5-56ff443173b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To Train from scratch/fine-tuning\n",
    "# encoder = create_model(\"fastvit_t8\", fork_feat=True) # can turn fork_feat to False\n",
    "\n",
    "# checkpoint = torch.load('./pretrained/fastvit_t8.pth.tar')\n",
    "# encoder.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "\n",
    "# # For inference\n",
    "# # model.eval()      \n",
    "# encoder = reparameterize_model(encoder)\n",
    "# encoder = encoder.to(device)\n",
    "# encoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba91844-672a-4a01-b5b2-092cdd1fe153",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "031936e1-5db6-4370-8be9-1f4431f32102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the decoder\n",
    "# decoder = UpsampleTransformerDecoderV2(\n",
    "#     input_channels=384,\n",
    "#     num_upsamples=5,  # Adjusted to 5 upsampling steps\n",
    "#     num_blocks=1,\n",
    "#     num_heads=16,\n",
    "#     ff_dim=4096,\n",
    "#     output_channels=3\n",
    "# )\n",
    "\n",
    "# # decoder_model_path = 'decoder_t8_preds_detr101dc5_adamw_numblocks_1_ffdim_4096_heads_16.pth'\n",
    "# # decoder_model_path = 'decoder_t8_preds_detr101dc5_adamw_numblocks_1_ffdim_4096_heads_16_v2.pth'\n",
    "# # decoder_model_path = './pretrained/decoder_state_dict_adamw_40e_numblocks_2_ffdim_4096_heads_16_mseloss_0.05.pth'\n",
    "# # decoder_model_path = 'decoder_v2_t8_preds_detr101dc5_adamw_numblocks_1_ffdim_4096_heads_32.pth'\n",
    "# decoder_model_path = 'decoder_v2_t8_preds_yolov8_adamw_numblocks_1_ffdim_4096_heads_16.pth'\n",
    "\n",
    "\n",
    "\n",
    "# # Load the state dictionary\n",
    "# decoder.load_state_dict(torch.load(decoder_model_path))\n",
    "\n",
    "# # This should be turned on only for test time. If we want to retrain, comment this line\n",
    "# # If you are using a GPU for the model, don't forget to move the decoder to the GPU\n",
    "# decoder.to(device)\n",
    "# decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40a5bcf2-92fb-434d-b3b1-c55c309e5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze encoder weights\n",
    "for param in autoencoder.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Freeze encoder weights\n",
    "for param in autoencoder.decoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Set up loss function and optimizer\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980786a7-ec3a-4896-a1bb-b388e847533d",
   "metadata": {},
   "source": [
    "## Avenue File Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21662bad-18c4-472d-b93d-53f282af1e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12ddd1ec-b2a4-44c9-8faa-ed0ec8e9a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection_utils import (\n",
    "    COLORS,\n",
    "    preprocess, \n",
    "    box_cxcywh_to_xyxy, \n",
    "    rescale_bboxes,\n",
    "    batch_detect,\n",
    "    detect, \n",
    "    plot_results,\n",
    "    plot_batch_detections,\n",
    "    plot_batch_detections,\n",
    "    plot_results_avenue,\n",
    "    load_images_from_folder,\n",
    "    list_image_files,\n",
    "    save_cropped_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daf42b1c-2d61-4a33-8e9a-d45b0126efc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/Avenue Dataset/test__/01 1439\n",
      "./datasets/Avenue Dataset/test__/02 1211\n",
      "./datasets/Avenue Dataset/test__/03 923\n",
      "./datasets/Avenue Dataset/test__/04 947\n",
      "./datasets/Avenue Dataset/test__/05 1007\n",
      "./datasets/Avenue Dataset/test__/06 1283\n",
      "./datasets/Avenue Dataset/test__/07 605\n",
      "./datasets/Avenue Dataset/test__/08 36\n",
      "./datasets/Avenue Dataset/test__/09 1175\n",
      "./datasets/Avenue Dataset/test__/10 841\n",
      "./datasets/Avenue Dataset/test__/11 472\n",
      "./datasets/Avenue Dataset/test__/12 1271\n",
      "./datasets/Avenue Dataset/test__/13 549\n",
      "./datasets/Avenue Dataset/test__/14 507\n",
      "./datasets/Avenue Dataset/test__/15 1001\n",
      "./datasets/Avenue Dataset/test__/16 740\n",
      "./datasets/Avenue Dataset/test__/17 426\n",
      "./datasets/Avenue Dataset/test__/18 294\n",
      "./datasets/Avenue Dataset/test__/19 248\n",
      "./datasets/Avenue Dataset/test__/20 273\n",
      "./datasets/Avenue Dataset/test__/21 76\n",
      "Total Frames: 15324\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"./datasets/Avenue Dataset/test__/\"\n",
    "test_video_dirs = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\"]\n",
    "test_video_paths = []\n",
    "total_frames = 0\n",
    "for dir in test_video_dirs:\n",
    "    cur_dir = os.path.join(test_dir, dir)\n",
    "    test_video_paths.append(cur_dir)\n",
    "    jpg_files = [f for f in os.listdir(cur_dir) if f.endswith('.jpg')]\n",
    "    total_frames += len(jpg_files)\n",
    "    print(cur_dir, len(jpg_files))\n",
    "print(f\"Total Frames: {total_frames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91d64aa4-fdb1-43ff-b40a-431c20cbd8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00.jpg', '01.jpg', '02.jpg', '03.jpg', '04.jpg', '05.jpg', '06.jpg', '07.jpg', '08.jpg', '09.jpg', '10.jpg', '11.jpg', '12.jpg', '13.jpg', '14.jpg', '15.jpg', '16.jpg', '17.jpg', '18.jpg', '19.jpg', '20.jpg', '21.jpg', '22.jpg', '23.jpg', '24.jpg', '25.jpg', '26.jpg', '27.jpg', '28.jpg', '29.jpg', '30.jpg', '31.jpg', '32.jpg', '33.jpg', '34.jpg', '35.jpg', '36.jpg', '37.jpg', '38.jpg', '39.jpg', '40.jpg', '41.jpg', '42.jpg', '43.jpg', '44.jpg', '45.jpg', '46.jpg', '47.jpg', '48.jpg', '49.jpg', '50.jpg', '51.jpg', '52.jpg', '53.jpg', '54.jpg', '55.jpg', '56.jpg', '57.jpg', '58.jpg', '59.jpg', '60.jpg', '61.jpg', '62.jpg', '63.jpg', '64.jpg', '65.jpg', '66.jpg', '67.jpg', '68.jpg', '69.jpg', '70.jpg', '71.jpg', '72.jpg', '73.jpg', '74.jpg', '75.jpg']\n"
     ]
    }
   ],
   "source": [
    "image_names = [img.split('/')[-1] for img in list_image_files(test_video_paths[-1])]\n",
    "print(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81acf25b-3044-40f2-ad3b-f9cf1a684ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = T.Compose([\n",
    "#     T.Resize((640, 360)),\n",
    "#     T.ToTensor(),\n",
    "#     T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad2ff88e-f1b3-4779-a9bc-30dfa367d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21']\n"
     ]
    }
   ],
   "source": [
    "video_names = [video.split('/')[-1] for video in test_video_paths]\n",
    "print(video_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "820922d5-98f0-4a00-aff9-d0eb7b4bc4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read obj_det_avenue_test\n",
    "with open('obj_dect_avenue_yolov8', 'rb') as file:\n",
    "    obj_dect_avenue = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "810f88bc-345d-4d55-ace0-57de6efd1e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/Avenue Dataset/test__/01\n",
      "./datasets/Avenue Dataset/test__/02\n",
      "./datasets/Avenue Dataset/test__/03\n",
      "./datasets/Avenue Dataset/test__/04\n",
      "./datasets/Avenue Dataset/test__/05\n",
      "./datasets/Avenue Dataset/test__/06\n",
      "./datasets/Avenue Dataset/test__/07\n",
      "./datasets/Avenue Dataset/test__/08\n",
      "./datasets/Avenue Dataset/test__/09\n",
      "./datasets/Avenue Dataset/test__/10\n",
      "./datasets/Avenue Dataset/test__/11\n",
      "./datasets/Avenue Dataset/test__/12\n",
      "./datasets/Avenue Dataset/test__/13\n",
      "./datasets/Avenue Dataset/test__/14\n",
      "./datasets/Avenue Dataset/test__/15\n",
      "./datasets/Avenue Dataset/test__/16\n",
      "./datasets/Avenue Dataset/test__/17\n",
      "./datasets/Avenue Dataset/test__/18\n",
      "./datasets/Avenue Dataset/test__/19\n",
      "./datasets/Avenue Dataset/test__/20\n",
      "./datasets/Avenue Dataset/test__/21\n",
      "CPU times: user 9min 11s, sys: 1min 23s, total: 10min 34s\n",
      "Wall time: 10min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_pred_ano = []\n",
    "anomaly_scores_dict = {}\n",
    "for i, video_path in enumerate(test_video_paths):\n",
    "    print(video_path)\n",
    "    image_names = [img.split('/')[-1] for img in list_image_files(test_video_paths[i])]\n",
    "\n",
    "    # Get dict containing {frame_idx: bounding boxes} for current video\n",
    "    bbox_temp = obj_dect_avenue[video_names[i]]\n",
    "\n",
    "    # For each video, all frames will have an associated anomaly score given by the max MLE loss on all objects in that frame\n",
    "    anomaly_scores_dict[video_names[i]] = {}\n",
    "\n",
    "    # Iterate through \n",
    "    for frame_idx, image_name in zip(bbox_temp, image_names):\n",
    "\n",
    "        # Get full path to frame/image\n",
    "        full_image_path = os.path.join(test_video_paths[i], image_name)\n",
    "\n",
    "        image = Image.open(full_image_path)\n",
    "\n",
    "        # Get list of bounding boxes\n",
    "        boxes = bbox_temp[frame_idx]\n",
    "\n",
    "        current_frame_max_anomaly_score = float('-inf')\n",
    "              \n",
    "        # Go through all bounding boxes of that frame, and crop the objects\n",
    "        for bbox in boxes:\n",
    "            cropped_obj = image.crop((bbox[0], bbox[1], bbox[2], bbox[3]))\n",
    "            \n",
    "            # Plot the cropped object for debugging\n",
    "            # cropped_obj.show()  # This will display the cropped image\n",
    "\n",
    "            # Transform cropped obj to desired 64 * 64 shape\n",
    "            transformed_obj = autoencoder_transform(cropped_obj)\n",
    "\n",
    "            # Ensure the transformed object is in the right shape for the model\n",
    "            transformed_obj = transformed_obj.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Forward pass through the encoder and then the decoder\n",
    "                # latent_representation = encoder(transformed_obj.to(device))[-1]  # Assuming the last output is the latent representation\n",
    "                # reconstructed_img = decoder(latent_representation)\n",
    "                reconstructed_img = autoencoder(transformed_obj.to(device))\n",
    "\n",
    "            # Ensure cropped_obj is a tensor and in the correct shape for loss calculation\n",
    "            cropped_obj_tensor = autoencoder_transform(cropped_obj)\n",
    "            cropped_obj_tensor = cropped_obj_tensor.unsqueeze(0) # Add batch dimension\n",
    "\n",
    "            # Compute the reconstruction loss\n",
    "            score = F.mse_loss(reconstructed_img, cropped_obj_tensor.to(device))\n",
    "\n",
    "            # We want to store the max anomaly score for this frame\n",
    "            if score > current_frame_max_anomaly_score:\n",
    "                current_frame_max_anomaly_score = score\n",
    "                anomaly_bbox = bbox\n",
    "            # current_frame_max_anomaly_score = max(score, current_frame_max_anomaly_score)\n",
    "\n",
    "            # print(score)\n",
    "\n",
    "            # We should now have bounding box, frame idx, maximum anomaly score, \n",
    "            # all_pred_ano.append(AnomalyDetection(frame_idx, bbox, score, video_names[i], track_id=-1))\n",
    "        all_pred_ano.append(AnomalyDetection(frame_idx, anomaly_bbox, score, video_names[i], track_id=-1))\n",
    "        \n",
    "        anomaly_scores_dict[video_names[i]][frame_idx] = current_frame_max_anomaly_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc12ebff-7e52-4c64-a55f-0d58e884dd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpr does not reach 1\n",
      "tbdc = 0.2126141460162959\n",
      "rbdc = 0.14000285037200888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14000285037200888, 0.2126141460162959)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_fpr_rbdr(all_pred_ano, gt_anomalies, all_gt_tracks, num_frames=15324, num_tracks=num_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a65b3-af4f-4dcc-8d81-a9fb4e85c6ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Dummy run with random score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a415c-f480-4ee9-a6d8-0b7ea754fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_pred_ano = []\n",
    "anomaly_scores_dict = {}\n",
    "for i, video_path in enumerate(test_video_paths):\n",
    "    print(video_path)\n",
    "    image_names = [img.split('/')[-1] for img in list_image_files(test_video_paths[i])]\n",
    "\n",
    "    # Get dict containing {frame_idx: bounding boxes} for current video\n",
    "    bbox_temp = obj_dect_avenue[video_names[i]]\n",
    "\n",
    "    # For each video, all frames will have an associated anomaly score given by the max MLE loss on all objects in that frame\n",
    "    anomaly_scores_dict[video_names[i]] = {}\n",
    "\n",
    "    # Iterate through \n",
    "    for frame_idx, image_name in zip(bbox_temp, image_names):\n",
    "\n",
    "        # Get full path to frame/image\n",
    "        full_image_path = os.path.join(test_video_paths[i], image_name)\n",
    "\n",
    "        image = Image.open(full_image_path)\n",
    "\n",
    "        # Get list of bounding boxes\n",
    "        boxes = bbox_temp[frame_idx]\n",
    "\n",
    "        # current_frame_max_anomaly_score = float('-inf')\n",
    "              \n",
    "        # # Go through all bounding boxes of that frame, and crop the objects\n",
    "        # for bbox in boxes:\n",
    "        #     cropped_obj = image.crop((bbox[0], bbox[1], bbox[2], bbox[3]))\n",
    "            \n",
    "        #     # Plot the cropped object for debugging\n",
    "        #     # cropped_obj.show()  # This will display the cropped image\n",
    "\n",
    "        #     # TODO: Transform cropped obj to desired 64 * 64 shape\n",
    "        #     transformed_obj = autoencoder_transform(cropped_obj)\n",
    "\n",
    "        #     # Ensure the transformed object is in the right shape for the model\n",
    "        #     transformed_obj = transformed_obj.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        #     with torch.no_grad():\n",
    "        #         # Forward pass through the encoder and then the decoder\n",
    "        #         latent_representation = encoder(transformed_obj.to(device))[-1]  # Assuming the last output is the latent representation\n",
    "        #         reconstructed_img = decoder(latent_representation)\n",
    "\n",
    "        #     # Ensure cropped_obj is a tensor and in the correct shape for loss calculation\n",
    "        #     cropped_obj_tensor = autoencoder_transform(cropped_obj)\n",
    "        #     cropped_obj_tensor = cropped_obj_tensor.unsqueeze(0) # Add batch dimension\n",
    "\n",
    "        #     # Compute the reconstruction loss\n",
    "        #     # score = F.mse_loss(reconstructed_img, cropped_obj_tensor.to(device))\n",
    "        #     score = random.random()\n",
    "\n",
    "        #     # We want to store the max anomaly score for this frame\n",
    "        #     current_frame_max_anomaly_score = max(score, current_frame_max_anomaly_score)\n",
    "\n",
    "        #     # print(score)\n",
    "\n",
    "        score = random.random()\n",
    "\n",
    "        # We should now have bounding box, frame idx, maximum anomaly score, \n",
    "        all_pred_ano.append(AnomalyDetection(frame_idx, bbox, score, video_names[i], track_id=-1))\n",
    "\n",
    "        anomaly_scores_dict[video_names[i]][frame_idx] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c657b33c-f153-4fde-aaf7-ae8c039a9f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_fpr_rbdr(all_pred_ano, gt_anomalies, all_gt_tracks, num_frames=15324, num_tracks=num_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02217710-0906-45f6-bc73-42a99c49352a",
   "metadata": {},
   "source": [
    "#### Save and load to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba36be-32c8-49ec-8012-10baf161026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the object to a file\n",
    "# with open(pickle_file, 'wb') as file:\n",
    "#     pickle.dump(all_pred_ano, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12f318-b0bf-401e-acff-47c2a465caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the object from the file\n",
    "# pickle_file = 'all_pred_ano_avenue_v3.pkl'\n",
    "# with open(pickle_file, 'rb') as file:\n",
    "#     all_pred_ano = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79edcaea-e39f-4f20-95a7-1d28c5f7cdc1",
   "metadata": {},
   "source": [
    "### Micro / Macro AUC Score\n",
    "\n",
    "- micro e cand concatenez toate video-urile si evaluez abilitatea de a detecta anomalii\n",
    "- macro e cand fac AUC pe fiecare video si fac medie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fb408fb-6ec4-42f6-bf5a-cc3737e5e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter(support, sigma):\n",
    "    mu = support[len(support) // 2 - 1]\n",
    "    # mu = np.mean(support)\n",
    "    filter = 1.0 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-0.5 * ((support - mu) / sigma) ** 2)\n",
    "    return filter\n",
    "\n",
    "def filt(input, dim=9, range=302, mu=25):\n",
    "    filter_3d = np.ones((dim, dim, dim)) / (dim ** 3)\n",
    "    filter_2d = gaussian_filter(np.arange(1, range), mu)\n",
    "\n",
    "    frame_scores = input # This works\n",
    "    # frame_scores = convolve(input, filter_3d)\n",
    "    # frame_scores = frame_scores.max((1, 2))\n",
    "\n",
    "    padding_size = len(filter_2d) // 2\n",
    "    in_ = np.concatenate((np.zeros(padding_size), frame_scores, np.zeros(padding_size)))\n",
    "    frame_scores = np.correlate(in_, filter_2d, 'valid')\n",
    "    return frame_scores\n",
    "\n",
    "def process_current_vid_preds(pred: np.array): \n",
    "    pred = np.nan_to_num(pred, nan=0.)\n",
    "    pred = filt(pred, range=302, mu=25)\n",
    "    pred = (pred - np.min(pred)) / (np.max(pred) - np.min(pred))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5263552-3ad0-48a4-b019-ee33dfbc3967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21'])\n"
     ]
    }
   ],
   "source": [
    "def read_txt_to_numpy_array(file_path):\n",
    "    try:\n",
    "        data = np.loadtxt(file_path)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "labels_path = './datasets/Avenue Dataset/gt/'\n",
    "labels_dict = {}\n",
    "\n",
    "for vid_name in anomaly_scores_dict:\n",
    "    labels_dict[vid_name] = read_txt_to_numpy_array(os.path.join(labels_path, f\"{vid_name}.txt\"))\n",
    "\n",
    "print(labels_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55d0a25d-9cbb-44b5-a746-28d6a8cfd261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels_dict['01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6205fba-bc2a-41b6-ae42-d972471d156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9642810b-826e-4315-b675-443c4ff3b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6002765828787121\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "filtered_preds = []\n",
    "filtered_labels = []\n",
    "\n",
    "for vid_name in anomaly_scores_dict:\n",
    "    # print(len(anomaly_scores_dict[vid_name]))\n",
    "    pred = np.array(list(tensor.cpu() for tensor in anomaly_scores_dict[vid_name].values()))\n",
    "    pred = process_current_vid_preds(pred)\n",
    "    filtered_preds.append(pred)\n",
    "\n",
    "    lbl = labels_dict[vid_name]\n",
    "    filtered_labels.append(lbl)\n",
    "\n",
    "    lbl = np.array([0] + list(lbl) + [1])\n",
    "    pred = np.array([0] + list(pred) + [1])\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(lbl, pred)\n",
    "    res = metrics.auc(fpr, tpr)\n",
    "    aucs.append(res)\n",
    "\n",
    "macro_auc = np.nanmean(aucs)\n",
    "print(macro_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "889035a4-c673-4056-9c2b-aea06cd68ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro-AUC\n",
    "filtered_preds = np.concatenate(filtered_preds)\n",
    "filtered_labels = np.concatenate(filtered_labels)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(filtered_labels, filtered_preds)\n",
    "micro_auc = metrics.auc(fpr, tpr)\n",
    "micro_auc = np.nan_to_num(micro_auc, nan=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "496cca44-2721-476f-be52-89a6ea433c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6007772307192685\n"
     ]
    }
   ],
   "source": [
    "print(micro_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6d526c-f2d1-4a48-89a5-bf47003b4b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c7665-ae8b-4eb9-9468-45ed653bb0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
